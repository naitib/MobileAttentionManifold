{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def download_url(url, save_path):\n",
    "    with urlopen(url) as dl_file:\n",
    "        with open(save_path, 'wb') as out_file:\n",
    "            out_file.write(dl_file.read())\n",
    "\n",
    "URL = 'https://datasets.d2.mpi-inf.mpg.de/MobileHCI2018/MPIIMobileAttention.zip'\n",
    "\n",
    "download_url(URL, '../MPIIMobileAttention.zip')\n",
    "\n",
    "print ('url downloaded :) \\n')\n",
    "\n",
    "# open and save the zip file onto computer\n",
    "url = urlopen(URL)\n",
    "output = open('./MPIIMobileAttention.zip', 'wb')    # note the flag:  \"wb\"  \n",
    "print ('opened \\n')      \n",
    "output.write(url.read())\n",
    "print ('written \\n')  \n",
    "output.close()\n",
    "print ('closed \\n')  \n",
    "\n",
    "# read the zip file as a pandas dataframe\n",
    "df = pd.read_pickle('MPIIMobileAttention.zip')    # zip files       \n",
    "print ('read a pkl \\n')  \n",
    "\n",
    "df.to_pickle(\"./MPIIMobileAttention.pkl\")\n",
    "print ('made a pkl \\n')  \n",
    "# if keeping on disk the zip file is not wanted, then:\n",
    "# os.remove(zipName)   # remove the copy of the zipfile on disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from urllib.request import urlopen, Request\n",
    "import pickle\n",
    "\n",
    "\n",
    "URL = 'https://datasets.d2.mpi-inf.mpg.de/MobileHCI2018/MPIIMobileAttention.zip'\n",
    "\n",
    "r = Request(URL)\n",
    "b2 = [z for z in URL.split('/') if '.zip' in z][0] #gets just the '.zip' part of the url\n",
    "\n",
    "with open(b2, \"wb\") as target:\n",
    "    target.write(urlopen(r).read()) # saves to file to disk\n",
    "\n",
    "zipfile = ZipFile(b2,'r')\n",
    "\n",
    "namelist = zipfile.namelist()\n",
    "print(namelist)\n",
    "\n",
    "\"\"\"\n",
    "f = zipfile.extractall()\n",
    "\n",
    "\"\"\"\n",
    "list_of_dfs = []\n",
    "\n",
    "for name in namelist:\n",
    "    df = pd.read_pickle(name)\n",
    "    list_of_dfs.append(df)\n",
    "\n",
    "big_df = pd.concat(list_of_dfs)\n",
    "\n",
    "print(list_of_dfs)\n",
    "\n",
    "big_df.to_pickle(\"./MPIIMobileAttention.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = big_df.dropna(axis='columns')\n",
    "\n",
    "df.dropna(axis=1, how='all')\n",
    "\n",
    "df.loc[:, df.ne(0).any()]\n",
    "\n",
    "df.fillna(df.mean())\n",
    "\n",
    "phone_df = df.loc[:,(df.columns.str.startswith(\"phone_\")) | (df.columns.str.startswith(\"app_\")) |\n",
    "                    (df.columns.str.startswith(\"touch_\")) | (df.columns.str.startswith(\"gps_\")) |\n",
    "                    (df.columns.str.startswith(\"screen\")) | (df.columns.str.startswith(\"disp\")) |\n",
    "                    (df.columns.str.startswith(\"whatsapp\")) | (df.columns.str.startswith(\"temp\")) |\n",
    "                    (df.columns.str.startswith(\"distance_cam\"))]\n",
    "rgb_df1 = df.loc[:,(df.columns.str.startswith(\"objectclass_\")) | (df.columns.str.startswith(\"objectness_\")) |\n",
    "                    (df.columns.str.startswith(\"saliency_\")) | (df.columns.str.startswith(\"segmentationclass_\"))]\n",
    "rgb_df2 = df[['object_seg', 'sem_seg',  'gaze_xundist', 'gaze_yundist', 'corner1_xundist', 'corner1_yundist',\n",
    "            'corner2_xundist', 'corner2_yundist', 'corner3_xundist', 'corner3_yundist',  'corner4_xundist',\n",
    "             'corner4_yundist', 'corner1_xundistext', 'corner1_yundistext', 'corner2_xundistext',\n",
    "             'corner2_yundistext','corner3_xundistext', 'corner3_yundistext', 'corner4_xundistext',\n",
    "             'corner4_yundistext','corner1ext_x', 'corner1ext_y', 'corner2ext_x', 'corner2ext_y',\n",
    "             'corner3ext_x', 'corner3ext_y','corner4ext_x', 'corner4ext_y', 'face_detections_world']]\n",
    "rgb_df = pd.concat([rgb_df1, rgb_df2], axis=1)\n",
    "\n",
    "headimu_df = df.loc[:,(df.columns.str.startswith(\"accelerometer_\")) | (df.columns.str.startswith(\"gyro_\")) |\n",
    "                    (df.columns.str.startswith(\"mobilephone_in_scene_vid\")) | (df.columns.str.startswith(\"corner1_x\")) | \n",
    "                    (df.columns.str.startswith(\"corner1_y\")) | (df.columns.str.startswith(\"corner2_y\")) |\n",
    "                    (df.columns.str.startswith(\"corner2_x\")) | (df.columns.str.startswith(\"corner3_x\")) |\n",
    "                    (df.columns.str.startswith(\"corner3_y\")) | (df.columns.str.startswith(\"corner4_x\")) |\n",
    "                    (df.columns.str.startswith(\"corner4_y\")) ]\n",
    "\n",
    "depth_df = df.loc[:,df.columns.str.startswith(\"depth_\")]\n",
    "\n",
    "gaze_df = df[['saliency', 'depth', 'objectness', 'pupil_x', 'pupil_y',\n",
    "            'gaze_x', 'gaze_y', 'diameter', 'major', 'minor', 'angle',\n",
    "            'fix_dispersions', 'fix_durations', 'fix_centroids_y',\n",
    "            'fix_centroids_x', 'fix_centroidsext_x', 'fix_centroidsext_y']]\n",
    "\n",
    "egocentric_df = pd.concat([headimu_df, pd.concat([rgb_df, depth_df], axis = 1)], axis = 1) # the egocentric sensors if we want to revisit as the paper did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([headimu_df, pd.concat([rgb_df, pd.concat([depth_df, pd.concat([phone_df, gaze_df], axis = 1)], axis = 1)], axis = 1)], axis = 1)\n",
    "X = pd.get_dummies(X)\n",
    "X= np.array(X).astype(np.float32)\n",
    "\n",
    "y = np.array(df['gaze_on_screen'])\n",
    "\n",
    "print('X: \\n', X.dtype, X)\n",
    "print('y: \\n',y.dtype, y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "from proximityMatrix import proximityMatrix\n",
    "\n",
    "proxMat = proximityMatrix(clf, X_train, normalize=True)\n",
    "\n",
    "print(\"proxMat: \\n\", proxMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to get current path rn\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMP\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = loadData(files[0:1])\n",
    "print(files[0:1])\n",
    "\n",
    "#features.head()\n",
    "\n",
    "with zipfile.open(name) as myfile:\n",
    "  df = pickle.load(myfile)\n",
    "\n",
    "\n",
    "df = df.drop(columns=['trust_screen', 'environment', 'indoor_outdoor','trust_activity',\n",
    "                       'user_name', 'message', 'app_description','stat_mobile',\n",
    "                       'screenstatus', 'screenactivity', 'phone_screenonoff_description',\n",
    "                       'sem_seg','subject_folder','block_folder', 'object_seg', 'question_type'])\n",
    "\n",
    "\n",
    "\n",
    "#'evironment_1', 'evironment_2', 'evironment_3', 'evironment_4', 'evironment_5', \n",
    "\n",
    "#df = df.fillna(0)\n",
    "\n",
    "#df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df = df.dropna(axis='columns')\n",
    "\n",
    "col_names = df.columns\n",
    "print(col_names)\n",
    "\n",
    "#df = pd.get_dummies(df)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "f = open(zipfile.NameToInfo.keys(),'wb')\n",
    "f.write(zipfile.open(zipfile.NameToInfo.keys()[0]).read())\n",
    "f.close()\n",
    "\n",
    "df = pd.read_pickle(zipfile.NameToInfo.keys()[0])\n",
    "\n",
    "\n",
    "# print(\"df: \\n\", df)\n",
    "# print(df.dtypes)\n",
    "\n",
    "# print (df)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\"\n",
    "text_files = zf.infolist()\n",
    "\n",
    "\n",
    "print (\"Uncompressing and reading data... \")\n",
    "\n",
    "for text_file in text_files:\n",
    "    print(text_file.filename)\n",
    "    df = pd.read_pickle(zf.open(text_file.filename))     # do df manipulations\n",
    "    list_of_dfs.append(df)\n",
    "\n",
    "big_df = pd.concat(list_of_dfs) # df = pd.read_pickle(b2, compression='zip')  #opens the saved zip file\n",
    "\n",
    "big_df = pd.concat(list_of_dfs, ignore_index = True, sort=True)\n",
    "os.remove(b2) #removes the zip file\n",
    "\n",
    "big_df.to_pickle(\"./MPIIMobileAttention.pkl\")\n",
    "\n",
    "\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
