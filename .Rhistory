}
# Simulate RTData using 20000 EEG features (could also be fMRI)
#simulating features by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.001) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#randomly sample 910 vals from sequence from 1 to 1000, so 90 nonzero coefficients now
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
# hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
Coeffs = rlnorm(20000,1,0.02) #ensure all positive so not using gaussian
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.02) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.02) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
# hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
?rlnorm
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.02) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.2) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.001) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.001) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.0002) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.0002) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.02) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.0002) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.2) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.0002) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.02) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
# Simulate RTData using 20000 EEG features (could also be fMRI)
# Do this by creating a matrix with a thousand random numbers chosen from log normal dist
NeurFeat = matrix(rlnorm(20000),nrow = 200, ncol = 20000) # 200 trials and 20000 features, default in lnorm
Coeffs = rlnorm(20000,1,0.0002) #ensure all positive so not using gaussian
Coeffs[sample(seq(1:length(Coeffs)),16000)] = 0 # set 16000 coeffs to 0 (80% of 20000)
#length(which(Coeffs == 0)) #find all indices of coeffs equal to zero and returns num coeffs equal to 0
RTData = rowSums(sweep(NeurFeat,MARGIN=2,Coeffs,'*')) #Milliseconds
#rowsums across rows after sweep function multiplies (*) each col of neurfeat with coeffs;
#simulating rxn time or response data based on eeg features, based on result of ersp
NRTData = RTData + rnorm(length(RTData), 0, 0.6*sd(RTData)) # 60% of data's std dev
# hist(noisyRTData)
# Histogram of RTData
hist(RTData)
# Since RTData is not a Gaussian distribution, we will log transform it to make it slightly more like gaus dist
#logRTData = log(RTData)
#hist(logRTData)
logNRTData = log(NRTData)
#hist(logNRTData)
# Split into training and testing data
TrainInds = sample(seq(1:length(NRTData)),length(NRTData)/2) #samples half (60 values) of the sequency of 1 to length(RTData)
TestInds = setdiff(seq(1:length(NRTData)),TrainInds) #setdifference, generate sequence and give all the indices that are not in train set
logNRTTrainData = logNRTData[TrainInds] #log of the RT data so we can use glmnet
logNRTTestData = logNRTData[TestInds]
NeurTrainData = NeurFeat[TrainInds,]
NeurTestData = NeurFeat[TestInds,]
# glmnet is elastic net, automatically tests range of lambdas
# Try to recover the Coefficients
eNetFit = glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)           # elastic-net regularization penalty
# this is glmnet not cross validation; it tunes based on cross validation holdout
cvENetTestPred = cv.glmnet(NeurTrainData,logNRTTrainData,
family = "gaussian",
alpha = 0.5)
eNetTestPred = predict(eNetFit,
NeurTestData,
s = cvENetTestPred$lambda.min)
# use min lambda we predicted and plot against test data
plot(exp(eNetTestPred),exp(logNRTTestData))
getwd()
?getwd
?c
ls
getwd()
setwd("Box/MobileAttentionManifoldProject/")
getwd()
